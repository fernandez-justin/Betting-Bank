{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# all the modeling imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# scoring, feature selection, and gridsearch\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('baseline_model.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non aggregates\n",
    "df_norm = pd.read_csv('data/pbp_data_mvp.csv')\n",
    "df_norm.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates (instantiating this up here as it needs columns from df_norm that will be dropped)\n",
    "df_norm_copy_for_attaching = df_norm[['Date','home_team','away_team','home_outcome','away_outcome','game_number_of_season']]\n",
    "df_agg = pd.read_csv('data/aggregate_data.csv')\n",
    "df_agg.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_prediction(X,y):\n",
    "    '''\n",
    "    This function will take input of the dataset split into the feature set and target\n",
    "    It runs logistic regression, decision tree, random forest, and xgboost\n",
    "    output train and test scores\n",
    "    '''\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=99)\n",
    "\n",
    "    # Scaling is Needed for Knn\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)  \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_base = LogisticRegression(random_state=99)\n",
    "    lr_base.fit(X_train,y_train)\n",
    "    pred_lr_base = lr_base.predict(X_train)\n",
    "    score_lr_base = accuracy_score(y_train,pred_lr_base)\n",
    "    \n",
    "    pred_lr_base_test = lr_base.predict(X_test)\n",
    "    score_lr_base_test = accuracy_score(y_test,pred_lr_base_test)\n",
    "    print('Logistic Regression Accuracy\\nTrain={} Test={}'.format(round(score_lr_base,3),round(score_lr_base_test,3)))\n",
    "    \n",
    "    # Decision Tree\n",
    "    tree_base = DecisionTreeClassifier(max_depth=15)\n",
    "    tree_base.fit(X_train,y_train)\n",
    "    pred_tree_base = tree_base.predict(X_train)\n",
    "    score_tree_base = accuracy_score(y_train,pred_tree_base)\n",
    "\n",
    "    pred_tree_base_test = tree_base.predict(X_test)\n",
    "    score_tree_base_test = accuracy_score(y_test,pred_tree_base_test)\n",
    "    print('Decision Tree Accuracy\\nTrain={} Test={}'.format(round(score_tree_base,3),round(score_tree_base_test,3)))\n",
    "\n",
    "          \n",
    "    # Random Forest\n",
    "    rand_base = RandomForestClassifier()\n",
    "    rand_base.fit(X_train,y_train)\n",
    "    pred_rand_base = rand_base.predict(X_train)\n",
    "    score_rand_base = accuracy_score(y_train,pred_rand_base)\n",
    "\n",
    "    pred_rand_base_test = rand_base.predict(X_test)\n",
    "    score_rand_base_test = accuracy_score(y_test,pred_rand_base_test)\n",
    "    print('Random Forest Accuracy\\nTrain={} Test={}'.format(round(score_rand_base,3),round(score_rand_base_test,3)))\n",
    "\n",
    "    \n",
    "    #XG Boost\n",
    "    xg_base = xgb.XGBClassifier(objecteve='binary:logistic')\n",
    "    xg_base.fit(X_train,y_train)\n",
    "    pred_xg_base = xg_base.predict(X_train)\n",
    "    score_xg_base = accuracy_score(y_train,pred_xg_base)\n",
    "\n",
    "    pred_xg_base_test = xg_base.predict(X_test)\n",
    "    score_xg_base_test = accuracy_score(y_test,pred_xg_base_test)\n",
    "    print('XGBoost Accuracy\\nTrain={} Test={}'.format(round(score_xg_base,3),round(score_xg_base_test,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Data (game per game stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in this data is the stats from one game. The target is the outcome of the next game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping the unnecessary cols that wont be used\n",
    "cols_to_drop = ['forfeit_info','lf_ump_id','rf_ump_id','protest_info',\n",
    "                'date_game_completed','additional_info','save_pitch_id',\n",
    "                'game_win_rbi_batter_id','game_in_series','away_catch_interference',\n",
    "                'home_catch_interference','away_pitch_balks',\n",
    "                'home_pitch_balks','day_of_week','away_league',\n",
    "                'away_team_game_number','home_league',\n",
    "                'home_team_game_number','day_or_night','park_id',\n",
    "                'attendance','time_of_game','away_line_scores',\n",
    "                'home_line_scores','year','id','outcome',\n",
    "               'Date','away_team','home_team']\n",
    "df_norm.drop(columns=cols_to_drop,inplace=True)\n",
    "df_norm.drop(df_norm.loc[:,'hb_ump_id':'acquisition_info'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PASO has some infinite values and those rows are dropped\n",
    "df_norm.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_norm.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating x and y\n",
    "X_norm = df_norm.drop(columns='target')\n",
    "y_norm = df_norm.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.536 Test=0.531\n",
      "Decision Tree Accuracy\n",
      "Train=0.633 Test=0.509\n",
      "Random Forest Accuracy\n",
      "Train=1.0 Test=0.522\n",
      "XGBoost Accuracy\n",
      "Train=0.566 Test=0.526\n"
     ]
    }
   ],
   "source": [
    "# baseline testing\n",
    "baseline_prediction(X_norm,y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game by game statistics (only using the last game to predict the next game) performs pretty well. Logistic regression perfoms the best and overfitting is very very low. Decision tree and random forest overfit a ton with very poor results on test. XG boost overfits slightly and performs the same as random forst. Will be doing more testing on logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the name of these becuase we already have the teams win % as this\n",
    "df_norm_copy_for_attaching.rename(columns={'home_outcome':'home_outcome_nonagg','away_outcome':'away_outcome_nonagg'},inplace=True)\n",
    "# merging to df\n",
    "df_agg = df_agg.merge(df_norm_copy_for_attaching,how='left',on=['Date','home_team','away_team'])\n",
    "# taking out the first 10 games due to them not having enough data\n",
    "df_agg_cutt_early = df_agg[(df_agg.game_number_of_season > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns no longer needed\n",
    "cols_to_drop_agg_cutt = ['home_team','away_team','Date','away_outcome_nonagg','game_number_of_season']\n",
    "df_agg_cutt_early.drop(columns=cols_to_drop_agg_cutt,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA/SO can result in infinite value, row dropped\n",
    "df_agg_cutt_early.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_agg_cutt_early.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is the outcome of current game\n",
    "X_agg_cutt = df_agg_cutt_early.drop(columns='home_outcome_nonagg')\n",
    "y_agg_cutt = df_agg_cutt_early.home_outcome_nonagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.564 Test=0.569\n",
      "Decision Tree Accuracy\n",
      "Train=0.799 Test=0.543\n",
      "Random Forest Accuracy\n",
      "Train=0.991 Test=0.526\n",
      "XGBoost Accuracy\n",
      "Train=0.608 Test=0.569\n"
     ]
    }
   ],
   "source": [
    "# baseline testing\n",
    "baseline_prediction(X_agg_cutt,y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the aggregate data performs better than the normal per game statistics data. The reason for this improvement is each team is not being assesed on only their previous game but all previous games that season. A team is not how well they did last game but how well they have been doing that season. One off game can throw off predictions. Logistic regression and XGBoost are going to be futher improved due to their accuracy in these intial tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection can be very useful by reducing the amount of features used in the model while also maintaining/increasing the accuracy score. A filter method of select k-best is going to be used first and then a wrapper method of recursive feature elimination after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a feature selector object\n",
    "feature_selector = SelectKBest(f_classif,50)\n",
    "\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "# features that we keep\n",
    "selected_filter = X_train.columns[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.56 Test=0.565\n",
      "Decision Tree Accuracy\n",
      "Train=0.78 Test=0.536\n",
      "Random Forest Accuracy\n",
      "Train=0.991 Test=0.53\n",
      "XGBoost Accuracy\n",
      "Train=0.605 Test=0.565\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction(X_agg_cutt[selected_filter],y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of feature pre feature selection: 76\n",
      "# of feature post feature selection: 50\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_cutt,y_agg_cutt,random_state=99)\n",
    "# we are going to use logistic regression as an estimator as it was the best performer in baseline tests\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "feature_selector = RFECV(estimator=estimator, step=1, cv=10,n_jobs=-1)\n",
    "\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "selected_wrapper = X_train.columns[feature_selector.support_]\n",
    "\n",
    "print('# of feature pre feature selection: {}'.format(len(X_train.columns)))\n",
    "print('# of feature post feature selection: {}'.format(len(selected_wrapper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.564 Test=0.568\n",
      "Decision Tree Accuracy\n",
      "Train=0.779 Test=0.531\n",
      "Random Forest Accuracy\n",
      "Train=0.991 Test=0.531\n",
      "XGBoost Accuracy\n",
      "Train=0.605 Test=0.566\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction(X_agg_cutt[selected_wrapper],y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recursive feature elimination produces slightly better results than the filter method. This shows that using 16 less features only decresed prediction accuracy by 0.001 for logistic regression and 0.003 for XGBoost. I am going to continue with the full dataset as computation time is not an issure in this project. I also believe that allowing as much information into the models will aloow for the highest accuracy as much as posssible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Depth Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the data we are going to use it is time to find the most optimal version of logistic regressiona and XGBoost as they were the best performers. Going to use grid search to find the best parameters for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the aggregated statistics\n",
    "\n",
    "The way that the aggregated stats are calculated are completelty different than the stats of the normal non-aggregated table. For aggregated stats the varibales are the average of the teams statistics up until that game and not including that current game. This allows us not to have to predict the outcome of the next game (the next game the home team plays) but the outcome of the game in that row. There is no data leakage because the stats from that game have not yet been added to the aggregated stats therefore it is not included in the teams average up until that game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_cutt,y_agg_cutt,random_state=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If restarting testing uncomment\n",
    "# If you want to see how differnt param grids stack up do no reinstantiate\n",
    "#param_grid_iterations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5610928053130169\n",
      "{'C': 100000000.0, 'max_iter': 800, 'penalty': 'l2'}\n",
      "LogisticRegression(C=100000000.0, max_iter=800)\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = { \n",
    "    'penalty': ['l2'],\n",
    "    'C': [1e9,1e8,1e7],\n",
    "    'max_iter':[600,700,800]\n",
    "}\n",
    "\n",
    "grid_lr=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid_lr, \n",
    "                         cv=10, \n",
    "                         scoring='accuracy', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(X_train,y_train)\n",
    "\n",
    "# Single best score achieved across all params\n",
    "print(grid_lr.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.565614\n",
      "Test Accuracy: 0.559477\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "y_pred_train = grid_lr.best_estimator_.predict(X_train)\n",
    "y_pred_test = grid_lr.best_estimator_.predict(X_test)\n",
    "# getting accuracy scores\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Train Accuracy: %f\" % (train_acc))\n",
    "print(\"Test Accuracy: %f\" % (test_acc))\n",
    "# add param grid and its respective test score to the list\n",
    "param_grid_iterations.append((grid_lr.best_params_,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'C': 10000, 'max_iter': 1000, 'penalty': 'l2'}, 0.5662605200351715)\n",
      "({'C': 100000.0, 'max_iter': 5000, 'penalty': 'l2'}, 0.5678934807185027)\n",
      "({'C': 10000000.0, 'max_iter': 5000, 'penalty': 'l2'}, 0.5671398065569652)\n",
      "({'C': 10000000.0, 'max_iter': 4000, 'penalty': 'l2'}, 0.5671398065569652)\n",
      "({'C': 10000000.0, 'max_iter': 2000, 'penalty': 'l2'}, 0.5671398065569652)\n",
      "({'C': 1000000000.0, 'max_iter': 80, 'penalty': 'l2'}, 0.5707825650043964)\n",
      "({'C': 1000000000.0, 'max_iter': 1000, 'penalty': 'l2'}, 0.5587237784197965)\n",
      "({'C': 1000000000.0, 'max_iter': 1000, 'penalty': 'l2'}, 0.5587237784197965)\n",
      "({'C': 100000000.0, 'max_iter': 800, 'penalty': 'l2'}, 0.559477452581334)\n",
      "({'C': 100000000.0, 'max_iter': 800, 'penalty': 'l2'}, 0.559477452581334)\n"
     ]
    }
   ],
   "source": [
    "# how did those param grids score\n",
    "for item in param_grid_iterations:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes from testing**\n",
    "* L2 after a couple iterations is the best penalty\n",
    "* higher C values and higher iterations allow for higher scores\n",
    "\n",
    "After a descent amount of testing I am going to chage the random state to see how that affects scores. The reason for this is because in previous testing I was able to achieve the highest scores through C=1e9, max_iter=80,and an l2 penalty.\n",
    "\n",
    "**After changing random state**\n",
    "\n",
    "After chaning random stat what previously gave quite good results not are not that great. The same trends as before are present in that C and max iteartions are trending towards higher values. L2 penalization is always the penalty the grid search chooses.\n",
    "\n",
    "**Final Notes from logistic regression grid search**\n",
    "\n",
    "From testing different sets of parameters on this problem, a high regularization score is favorable. L2 is the best performing penalty. Max iterations seems to converge to 80. All of these have the same score but will end with 80 as it has the least iterations but also the same score.\n",
    "\n",
    "From this we can see the the best logistic regression achieved a score of 57%. This is very good as it is 7% above being completely random which can help inform what team to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining Feature Importances\n",
    "Logistic regression assings weights to every feature and this is how it makes predictions upon on input. The feature values of that input are then used in a linear combination with the weights to obtain a score. If this score is above a certain threshold it predicts 0 and if below that threshold it predicts 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot use above grid search model, defining new model with same params as best model\n",
    "lr_final = LogisticRegression(penalty='l2',C=1e9,max_iter=80)\n",
    "lr_final.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling out the feature coefficients (weights) along with the respective features\n",
    "feature_importance = lr_final.coef_[0]\n",
    "features = X_agg_cutt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through and sorting by the highest weights (most impacting)\n",
    "feature_importance_list = []\n",
    "for feature, importance in zip(features,feature_importance):\n",
    "    feature_importance_list.append((feature,importance))\n",
    "feature_importance_list.sort(key=lambda x: np.abs(x[1]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('away_at_bats', -0.04345678209051356),\n",
       " ('home_at_bats', -0.04260631266103364),\n",
       " ('away_def_putouts', -0.03404399300307917),\n",
       " ('home_def_putouts', -0.031812435006491196),\n",
       " ('home_total_bases', -0.01812287965758287),\n",
       " ('away_total_bases', -0.013503773002808774),\n",
       " ('away_def_assists', -0.011995252966007584),\n",
       " ('away_so', -0.010932023522150374),\n",
       " ('home_hits', -0.01016044205761474),\n",
       " ('away_hits', -0.01008158397118806),\n",
       " ('home_so', -0.009996888220494748),\n",
       " ('away_pitch_earned_runs', -0.009064026657708887),\n",
       " ('away_team_earned_runs', -0.009043280913995175),\n",
       " ('home_pitch_earned_runs', -0.008213233992382118),\n",
       " ('home_team_earned_runs', -0.008202658745812047),\n",
       " ('home_left_on_base', -0.007664340582355865),\n",
       " ('away_singles', -0.0075775829415152055),\n",
       " ('home_def_assists', -0.007176331760961912),\n",
       " ('away_PASO', -0.006296537633368216),\n",
       " ('away_left_on_base', -0.0062134423405349115)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_list[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Seach of XGBoost will hopefully allow for good predictions as well as easily obtain feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [300,500],\n",
    "              'learning_rate': [1,0.1,0.01],\n",
    "              'max_depth': [5, 7, 10],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.fit(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_agg, X_test_agg, y_train_agg, y_test_agg = train_test_split(X_agg,y_agg,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XG Boost\n",
    "xg_gridv1 = xgb.XGBClassifier(objecteve='binary:logistic',\n",
    "                           colsample_bytree=0.4,\n",
    "                           learning_rate=0.2,\n",
    "                           max_depth=7,\n",
    "                           min_child_weight=3,\n",
    "                            n_estimators=300)\n",
    "xg_gridv1.fit(X_train_agg,y_train_agg)\n",
    "pred_xg_gridv1 = xg_gridv1.predict(X_train_agg)\n",
    "score_xg_gridv1 = accuracy_score(y_train_agg,pred_xg_gridv1)\n",
    "print('XGBoost Accuracy: {}'.format(score_xg_gridv1))\n",
    "\n",
    "pred_xg_gridv1_test = xg_gridv1.predict(X_test_agg)\n",
    "score_xg_gridv1_test = accuracy_score(y_test_agg,pred_xg_gridv1_test)\n",
    "print('XGBoost Test Accuracy: {}'.format(score_xg_gridv1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
