{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# all the modeling imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# scoring, feature selection, and gridsearch\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('baseline_model.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing normal dataset first\n",
    "df_norm = pd.read_csv('data/pbp_data_mvp.csv')\n",
    "df_norm.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_copy_for_attaching = df_norm[['Date','home_team','away_team','home_outcome','away_outcome','game_number_of_season']]\n",
    "df_agg = pd.read_csv('data/aggregate_data.csv')\n",
    "df_agg.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_prediction(X,y):\n",
    "    '''\n",
    "    This function will take input of the dataset split into the feature set and target\n",
    "    It runs logistic regression, decision tree, random forest, and xgboost\n",
    "    output train and test scores\n",
    "    '''\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=99)\n",
    "\n",
    "    # Scaling is Needed for Knn\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)  \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_base = LogisticRegression(random_state=99)\n",
    "    lr_base.fit(X_train,y_train)\n",
    "    pred_lr_base = lr_base.predict(X_train)\n",
    "    score_lr_base = accuracy_score(y_train,pred_lr_base)\n",
    "    \n",
    "    pred_lr_base_test = lr_base.predict(X_test)\n",
    "    score_lr_base_test = accuracy_score(y_test,pred_lr_base_test)\n",
    "    print('Logistic Regression Accuracy\\nTrain={} Test={}'.format(round(score_lr_base,3),round(score_lr_base_test,3)))\n",
    "    \n",
    "    # Decision Tree\n",
    "    tree_base = DecisionTreeClassifier(max_depth=15)\n",
    "    tree_base.fit(X_train,y_train)\n",
    "    pred_tree_base = tree_base.predict(X_train)\n",
    "    score_tree_base = accuracy_score(y_train,pred_tree_base)\n",
    "\n",
    "    pred_tree_base_test = tree_base.predict(X_test)\n",
    "    score_tree_base_test = accuracy_score(y_test,pred_tree_base_test)\n",
    "    print('Decision Tree Accuracy\\nTrain={} Test={}'.format(round(score_tree_base,3),round(score_tree_base_test,3)))\n",
    "\n",
    "          \n",
    "    # Random Forest\n",
    "    rand_base = RandomForestClassifier()\n",
    "    rand_base.fit(X_train,y_train)\n",
    "    pred_rand_base = rand_base.predict(X_train)\n",
    "    score_rand_base = accuracy_score(y_train,pred_rand_base)\n",
    "\n",
    "    pred_rand_base_test = rand_base.predict(X_test)\n",
    "    score_rand_base_test = accuracy_score(y_test,pred_rand_base_test)\n",
    "    print('Random Forest Accuracy\\nTrain={} Test={}'.format(round(score_rand_base,3),round(score_rand_base_test,3)))\n",
    "\n",
    "    \n",
    "    #XG Boost\n",
    "    xg_base = xgb.XGBClassifier(objecteve='binary:logistic')\n",
    "    xg_base.fit(X_train,y_train)\n",
    "    pred_xg_base = xg_base.predict(X_train)\n",
    "    score_xg_base = accuracy_score(y_train,pred_xg_base)\n",
    "\n",
    "    pred_xg_base_test = xg_base.predict(X_test)\n",
    "    score_xg_base_test = accuracy_score(y_test,pred_xg_base_test)\n",
    "    print('XGBoost Accuracy\\nTrain={} Test={}'.format(round(score_xg_base,3),round(score_xg_base_test,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Data (game per game stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in this data is the stats from one game. The target is the outcome of the next game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping the unnecessary cols that wont be used\n",
    "cols_to_drop = ['forfeit_info','lf_ump_id','rf_ump_id','protest_info',\n",
    "                'date_game_completed','additional_info','save_pitch_id',\n",
    "                'game_win_rbi_batter_id','game_in_series','away_catch_interference',\n",
    "                'home_catch_interference','away_pitch_balks',\n",
    "                'home_pitch_balks','day_of_week','away_league',\n",
    "                'away_team_game_number','home_league',\n",
    "                'home_team_game_number','day_or_night','park_id',\n",
    "                'attendance','time_of_game','away_line_scores',\n",
    "                'home_line_scores','year','id','outcome',\n",
    "               'Date','away_team','home_team']\n",
    "df_norm.drop(columns=cols_to_drop,inplace=True)\n",
    "df_norm.drop(df_norm.loc[:,'hb_ump_id':'acquisition_info'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PASO has some infinite values and those rows are dropped\n",
    "df_norm.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_norm.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating x and y\n",
    "X_norm = df_norm.drop(columns='target')\n",
    "y_norm = df_norm.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.536 Test=0.531\n",
      "Decision Tree Accuracy\n",
      "Train=0.633 Test=0.509\n",
      "Random Forest Accuracy\n",
      "Train=1.0 Test=0.522\n",
      "XGBoost Accuracy\n",
      "Train=0.566 Test=0.526\n"
     ]
    }
   ],
   "source": [
    "# baseline testing\n",
    "baseline_prediction(X_norm,y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game by game statistics (only using the last game to predict the next game) performs pretty well. Logistic regression perfoms the best and overfitting is very very low. Decision tree and random forest overfit a ton with very poor results on test. XG boost overfits slightly and performs the same as random forst. Will be doing more testing on logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the name of these becuase we already have the teams win % as this\n",
    "df_norm_copy_for_attaching.rename(columns={'home_outcome':'home_outcome_nonagg','away_outcome':'away_outcome_nonagg'},inplace=True)\n",
    "# merging to df\n",
    "df_agg = df_agg.merge(df_norm_copy_for_attaching,how='left',on=['Date','home_team','away_team'])\n",
    "# taking out the first 10 games due to them not having enough data\n",
    "df_agg_cutt_early = df_agg[(df_agg.game_number_of_season > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns no longer needed\n",
    "cols_to_drop_agg_cutt = ['home_team','away_team','Date','away_outcome_nonagg','game_number_of_season']\n",
    "df_agg_cutt_early.drop(columns=cols_to_drop_agg_cutt,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA/SO can result in infinite value, row dropped\n",
    "df_agg_cutt_early.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_agg_cutt_early.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is the outcome of current game\n",
    "X_agg_cutt = df_agg_cutt_early.drop(columns='home_outcome_nonagg')\n",
    "y_agg_cutt = df_agg_cutt_early.home_outcome_nonagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.564 Test=0.569\n",
      "Decision Tree Accuracy\n",
      "Train=0.799 Test=0.543\n",
      "Random Forest Accuracy\n",
      "Train=0.991 Test=0.526\n",
      "XGBoost Accuracy\n",
      "Train=0.608 Test=0.569\n"
     ]
    }
   ],
   "source": [
    "# baseline testing\n",
    "baseline_prediction(X_agg_cutt,y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the aggregate data performs better than the normal per game statistics data. The reason for this improvement is each team is not being assesed on only their previous game but all previous games that season. A team is not how well they did last game but how well they have been doing that season. One off game can throw off predictions. Logistic regression and XGBoost are going to be futher improved due to their accuracy in these intial tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection can be very useful by reducing the amount of features used in the model while also maintaining/increasing the accuracy score. A filter method of select k-best is going to be used first and then a wrapper method of recursive feature elimination after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a feature selector object\n",
    "feature_selector = SelectKBest(f_classif,50)\n",
    "\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "# features that we keep\n",
    "selected_filter = X_train.columns[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.56 Test=0.565\n",
      "Decision Tree Accuracy\n",
      "Train=0.78 Test=0.536\n",
      "Random Forest Accuracy\n",
      "Train=0.991 Test=0.53\n",
      "XGBoost Accuracy\n",
      "Train=0.605 Test=0.565\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction(X_agg_cutt[selected_filter],y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of feature pre feature selection: 76\n",
      "# of feature post feature selection: 50\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_cutt,y_agg_cutt,random_state=99)\n",
    "# we are going to use logistic regression as an estimator as it was the best performer in baseline tests\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "feature_selector = RFECV(estimator=estimator, step=1, cv=10,n_jobs=-1)\n",
    "\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "selected_wrapper = X_train.columns[feature_selector.support_]\n",
    "\n",
    "print('# of feature pre feature selection: {}'.format(len(X_train.columns)))\n",
    "print('# of feature post feature selection: {}'.format(len(selected_wrapper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy\n",
      "Train=0.564 Test=0.568\n",
      "Decision Tree Accuracy\n",
      "Train=0.779 Test=0.531\n",
      "Random Forest Accuracy\n",
      "Train=0.991 Test=0.531\n",
      "XGBoost Accuracy\n",
      "Train=0.605 Test=0.566\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction(X_agg_cutt[selected_wrapper],y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recursive feature elimination produces slightly better results than the filter method. This shows that using 16 less features only decresed prediction accuracy by 0.001 for logistic regression and 0.003 for XGBoost. I am going to continue with the full dataset as computation time is not an issure in this project. I also believe that allowing as much information into the models will increase accuracy as much as posssible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Depth Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the data we are going to use it is time to find the most optimal version of logistic regressiona and XGBoost as they were the best performers. Going to use grid search to find the best parameters for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the aggregated statistics\n",
    "\n",
    "The way that the aggregated stats are calculated are completelty different than the stats of the normal non-aggregated table. For aggregated stats the varibales are the average of the teams statistics up until that game and not including that current game. This allows us not to have to predict the outcome of the next game (the next game the home team plays) but the outcome of the game in that row. There is no data leakage because the stats from that game have not yet been added to the aggregated stats therefore it is not included in the teams average up until that game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_cutt,y_agg_cutt,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_iterations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5608405148387396\n",
      "{'C': 1000000000.0, 'max_iter': 80, 'penalty': 'l2'}\n",
      "LogisticRegression(C=1000000000.0, max_iter=80)\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = { \n",
    "    'penalty': ['l2','l1'],\n",
    "    'C': [1e10,1e9,1e8],\n",
    "    'max_iter':[60,80,100]\n",
    "}\n",
    "\n",
    "grid_lr=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid_lr, \n",
    "                         cv=10, \n",
    "                         scoring='accuracy', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(X_train,y_train)\n",
    "\n",
    "# Single best score achieved across all params\n",
    "print(grid_lr.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.563604\n",
      "Test Accuracy: 0.570783\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "y_pred_train = grid_lr.best_estimator_.predict(X_train)\n",
    "y_pred_test = grid_lr.best_estimator_.predict(X_test)\n",
    "# getting accuracy scores\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Train Accuracy: %f\" % (train_acc))\n",
    "print(\"Test Accuracy: %f\" % (test_acc))\n",
    "\n",
    "param_grid_iterations.append((grid_lr.best_params_,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'C': 1000000000.0, 'max_iter': 100, 'penalty': 'l2'}, 0.5707825650043964)\n",
      "({'C': 1000000000.0, 'max_iter': 80, 'penalty': 'l2'}, 0.5707825650043964)\n",
      "({'C': 1000000000.0, 'max_iter': 80, 'penalty': 'l2'}, 0.5707825650043964)\n"
     ]
    }
   ],
   "source": [
    "for item in param_grid_iterations:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From testing different parameter grids this problem we can see that this proble favors a very regularization score. L2 also is the best performing penalty. Max iterations seems to converge to 80. All of these have the same score but will end with 80 as it has the least iterations but also the same score.\n",
    "\n",
    "From this we can see the the best logistic regression achieved a score of 57%. This is very good as it is 7% above being completely random which can help inform what team to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression(penalty='l2',C=1e9,max_iter=80)\n",
    "lr_final.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lr_final.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_agg_cutt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_list = []\n",
    "for feature, importance in zip(features,feature_importance):\n",
    "    feature_importance_list.append((feature,importance))\n",
    "feature_importance_list.sort(key=lambda x: np.abs(x[1]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('away_at_bats', -0.04345678209051356),\n",
       " ('home_at_bats', -0.04260631266103364),\n",
       " ('away_def_putouts', -0.03404399300307917),\n",
       " ('home_def_putouts', -0.031812435006491196),\n",
       " ('home_total_bases', -0.01812287965758287),\n",
       " ('away_total_bases', -0.013503773002808774),\n",
       " ('away_def_assists', -0.011995252966007584),\n",
       " ('away_so', -0.010932023522150374),\n",
       " ('home_hits', -0.01016044205761474),\n",
       " ('away_hits', -0.01008158397118806)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to use XG boost for now as it perfomed the best out of all combinations. This will be using the aggregated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [300,500],\n",
    "              'learning_rate': [1,0.1,0.01],\n",
    "              'max_depth': [5, 7, 10],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.fit(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_agg, X_test_agg, y_train_agg, y_test_agg = train_test_split(X_agg,y_agg,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XG Boost\n",
    "xg_gridv1 = xgb.XGBClassifier(objecteve='binary:logistic',\n",
    "                           colsample_bytree=0.4,\n",
    "                           learning_rate=0.2,\n",
    "                           max_depth=7,\n",
    "                           min_child_weight=3,\n",
    "                            n_estimators=300)\n",
    "xg_gridv1.fit(X_train_agg,y_train_agg)\n",
    "pred_xg_gridv1 = xg_gridv1.predict(X_train_agg)\n",
    "score_xg_gridv1 = accuracy_score(y_train_agg,pred_xg_gridv1)\n",
    "print('XGBoost Accuracy: {}'.format(score_xg_gridv1))\n",
    "\n",
    "pred_xg_gridv1_test = xg_gridv1.predict(X_test_agg)\n",
    "score_xg_gridv1_test = accuracy_score(y_test_agg,pred_xg_gridv1_test)\n",
    "print('XGBoost Test Accuracy: {}'.format(score_xg_gridv1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Feature Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Data cutting first 10 games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_cutt,y_agg_cutt,random_state=99)\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "feature_selector = RFECV(estimator=estimator, step=1, cv=10,n_jobs=-1,min_features_to_select=15)\n",
    "\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "selected_wrapper = X_train.columns[feature_selector.support_]\n",
    "\n",
    "print('# of feature pre feature selection: {}'.format(len(X_train.columns)))\n",
    "print('# of feature post feature selection: {}'.format(len(selected_wrapper)))\n",
    "\n",
    "baseline_prediction(X_agg[selected_wrapper],y_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection using the wrapper method actually saw a loss in performance in almost every metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid_lr = { \n",
    "    'penalty': ['l2','l1','elasticnet'],\n",
    "    'C': [0.1,0.05,0.01],\n",
    "    'max_iter':[1000],\n",
    "    \n",
    "}\n",
    "\n",
    "grid_lr=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid_lr, \n",
    "                         cv=10, \n",
    "                         scoring='accuracy', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(X_train,y_train)\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_lr.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred_test = grid_lr.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred_train = grid_lr.best_estimator_.predict(X_train)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Train Accuracy: %f\" % (train_acc))\n",
    "print(\"Test Accuracy: %f\" % (test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XG Boost\n",
    "xg_cutt = xgb.XGBClassifier(objecteve='binary:logistic')\n",
    "xg_cutt.fit(X_train_agg_cutt,y_train_agg_cutt)\n",
    "pred_xg_cutt = xg_cutt.predict(X_train_agg_cutt)\n",
    "score_xg_cutt = accuracy_score(y_train_agg_cutt,pred_xg_cutt)\n",
    "print('XGBoost Accuracy: {}'.format(score_xg_cutt))\n",
    "\n",
    "pred_xg_cutt_test = xg_cutt.predict(X_test_agg_cutt)\n",
    "score_xg_cutt_test = accuracy_score(y_test_agg_cutt,pred_xg_cutt_test)\n",
    "print('XGBoost Test Accuracy: {}'.format(score_xg_cutt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_cutt,max_num_features = 15)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.away_int_walk.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "pred_gnb = gnb.predict(X_train)\n",
    "score_gnb = accuracy_score(y_train,pred_gnb)\n",
    "print(score_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(C=0.05,penalty='l2',max_iter=1000)\n",
    "clf2 = xgb.XGBClassifier()\n",
    "clf3 = DecisionTreeClassifier()\n",
    "eclf = VotingClassifier(estimators=[('lr',clf1),('xg',clf2),('dt',clf3)],\n",
    "                        voting='hard')\n",
    "eclf.fit(X_train,y_train)\n",
    "eclf_preds = eclf.predict(X_train)\n",
    "eclf_score = accuracy_score(y_train,eclf_preds)\n",
    "print(eclf_score)\n",
    "\n",
    "eclf_preds_test = eclf.predict(X_test)\n",
    "eclf_score_test = accuracy_score(y_test,eclf_preds_test)\n",
    "print(eclf_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
